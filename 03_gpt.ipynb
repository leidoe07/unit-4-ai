{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 1.09Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:00, 2.04Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 4.54Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [06:10, 1.34Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 3.31Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.52Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 2.87Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#gpt2.download_gpt2(\n",
    "   # model_name='124M'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name='124M',reuse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 =gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547121.647828 4553597 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 20.01] loss=4.16 avg=4.16\n",
      "[2 | 40.38] loss=3.81 avg=3.99\n",
      "[3 | 58.60] loss=3.71 avg=3.89\n",
      "[4 | 76.52] loss=3.44 avg=3.78\n",
      "[5 | 96.07] loss=3.88 avg=3.80\n",
      "[6 | 115.65] loss=3.69 avg=3.78\n",
      "[7 | 134.85] loss=3.87 avg=3.79\n",
      "[8 | 153.57] loss=3.70 avg=3.78\n",
      "[9 | 171.44] loss=3.58 avg=3.76\n",
      "[10 | 188.77] loss=3.38 avg=3.72\n",
      "[11 | 207.82] loss=3.61 avg=3.71\n",
      "[12 | 225.90] loss=3.51 avg=3.69\n",
      "[13 | 243.62] loss=3.71 avg=3.69\n",
      "[14 | 262.73] loss=3.65 avg=3.69\n",
      "[15 | 281.63] loss=3.53 avg=3.68\n",
      "[16 | 298.63] loss=3.39 avg=3.66\n",
      "[17 | 315.59] loss=3.49 avg=3.65\n",
      "[18 | 334.26] loss=3.41 avg=3.63\n",
      "[19 | 353.22] loss=3.30 avg=3.61\n",
      "[20 | 371.37] loss=3.21 avg=3.59\n",
      "[21 | 389.99] loss=3.60 avg=3.59\n",
      "[22 | 411.08] loss=3.49 avg=3.59\n",
      "[23 | 431.06] loss=3.40 avg=3.58\n",
      "[24 | 450.20] loss=3.52 avg=3.58\n",
      "[25 | 469.67] loss=3.40 avg=3.57\n",
      "[26 | 489.27] loss=3.65 avg=3.57\n",
      "[27 | 509.35] loss=3.58 avg=3.57\n",
      "[28 | 529.03] loss=3.60 avg=3.57\n",
      "[29 | 547.97] loss=3.39 avg=3.57\n",
      "[30 | 567.67] loss=3.73 avg=3.57\n",
      "[31 | 586.83] loss=3.46 avg=3.57\n",
      "[32 | 604.77] loss=3.08 avg=3.55\n",
      "[33 | 623.25] loss=3.51 avg=3.55\n",
      "[34 | 643.52] loss=3.39 avg=3.54\n",
      "[35 | 663.97] loss=3.20 avg=3.53\n",
      "[36 | 683.36] loss=3.33 avg=3.52\n",
      "[37 | 704.35] loss=3.24 avg=3.52\n",
      "[38 | 725.45] loss=3.65 avg=3.52\n",
      "[39 | 745.57] loss=3.17 avg=3.51\n",
      "[40 | 765.11] loss=3.47 avg=3.51\n",
      "[41 | 784.51] loss=3.17 avg=3.50\n",
      "[42 | 803.49] loss=3.42 avg=3.50\n",
      "[43 | 822.68] loss=3.39 avg=3.49\n",
      "[44 | 841.40] loss=3.61 avg=3.50\n",
      "[45 | 859.42] loss=3.41 avg=3.49\n",
      "[46 | 878.66] loss=3.34 avg=3.49\n",
      "[47 | 897.34] loss=3.18 avg=3.48\n",
      "[48 | 915.73] loss=3.34 avg=3.48\n",
      "[49 | 935.06] loss=3.52 avg=3.48\n",
      "[50 | 954.57] loss=3.08 avg=3.47\n",
      "[51 | 973.46] loss=3.36 avg=3.47\n",
      "[52 | 992.96] loss=3.32 avg=3.46\n",
      "[53 | 1012.05] loss=3.23 avg=3.46\n",
      "[54 | 1031.90] loss=3.37 avg=3.45\n",
      "[55 | 1052.88] loss=3.49 avg=3.46\n",
      "[56 | 1071.92] loss=3.22 avg=3.45\n",
      "[57 | 1090.28] loss=3.41 avg=3.45\n",
      "[58 | 1108.83] loss=3.14 avg=3.44\n",
      "[59 | 1126.56] loss=3.12 avg=3.43\n",
      "[60 | 1143.57] loss=3.34 avg=3.43\n",
      "[61 | 1160.20] loss=3.22 avg=3.43\n",
      "[62 | 1178.68] loss=3.08 avg=3.42\n",
      "[63 | 1195.14] loss=3.24 avg=3.42\n",
      "[64 | 1211.80] loss=3.43 avg=3.42\n",
      "[65 | 1230.43] loss=3.44 avg=3.42\n",
      "[66 | 1248.28] loss=3.11 avg=3.41\n",
      "[67 | 1265.27] loss=3.28 avg=3.41\n",
      "[68 | 1282.56] loss=3.45 avg=3.41\n",
      "[69 | 1300.59] loss=3.37 avg=3.41\n",
      "[70 | 1317.42] loss=3.08 avg=3.40\n",
      "[71 | 1335.83] loss=3.52 avg=3.40\n",
      "[72 | 1356.40] loss=3.42 avg=3.40\n",
      "[73 | 1375.07] loss=3.06 avg=3.40\n",
      "[74 | 1393.78] loss=3.14 avg=3.39\n",
      "[75 | 1412.21] loss=3.23 avg=3.39\n",
      "[76 | 1431.11] loss=3.30 avg=3.39\n",
      "[77 | 1448.80] loss=3.25 avg=3.39\n",
      "[78 | 1468.18] loss=3.08 avg=3.38\n",
      "[79 | 1486.90] loss=3.40 avg=3.38\n",
      "[80 | 1506.38] loss=3.20 avg=3.38\n",
      "[81 | 1525.01] loss=3.26 avg=3.37\n",
      "[82 | 1543.32] loss=3.28 avg=3.37\n",
      "[83 | 1562.06] loss=3.42 avg=3.37\n",
      "[84 | 1579.74] loss=3.37 avg=3.37\n",
      "[85 | 1598.97] loss=3.20 avg=3.37\n",
      "[86 | 1616.91] loss=3.09 avg=3.37\n",
      "[87 | 1635.16] loss=3.12 avg=3.36\n",
      "[88 | 1654.10] loss=3.41 avg=3.36\n",
      "[89 | 1672.33] loss=3.19 avg=3.36\n",
      "[90 | 1690.28] loss=3.42 avg=3.36\n",
      "[91 | 1710.56] loss=3.22 avg=3.36\n",
      "[92 | 1729.27] loss=3.11 avg=3.35\n",
      "[93 | 1748.05] loss=3.33 avg=3.35\n",
      "[94 | 1767.85] loss=3.23 avg=3.35\n",
      "[95 | 1787.41] loss=3.18 avg=3.35\n",
      "[96 | 1806.12] loss=2.94 avg=3.34\n",
      "[97 | 1826.51] loss=2.80 avg=3.33\n",
      "[98 | 1845.05] loss=3.13 avg=3.33\n",
      "[99 | 1863.26] loss=3.34 avg=3.33\n",
      "[100 | 1882.46] loss=2.95 avg=3.32\n",
      "Saving checkpoint/shakespeare/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    'shakespeare.txt',\n",
    "    model_name='124M',\n",
    "    steps=100,\n",
    "    run_name='shakespeare'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leilani : Now you shall die,\n",
      "And my baby shall live.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "Let me beseech you, my sweet lord,\n",
      "Commit your life to my care,\n",
      "And this wife to the king.\n",
      "\n",
      "POMPEY:\n",
      "I pray you, my lord, you shall live.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "And this daughter shall live too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall live too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall live too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have heard your lord say 'Hear me, hear me,'\n",
      "And your lord say 'There's a keeper, here's a keeper.'\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POMPEY:\n",
      "My lord, you shall die too.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, you shall die too.\n",
      "\n",
      "POM\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix='Leilani : Now you shall die',\n",
    "    run_name='shakespeare'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
